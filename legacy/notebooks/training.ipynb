{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: imports + retriever\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class QuantumWalkRetriever(nn.Module):\n",
    "    def __init__(self, embed_model_name='all-MiniLM-L6-v2', k=5, hidden_dim=128, walk_steps=3):\n",
    "        super().__init__()\n",
    "        self.embedder = SentenceTransformer(embed_model_name)\n",
    "        for p in self.embedder.parameters(): p.requires_grad = False\n",
    "        self.k, self.walk_steps = k, walk_steps\n",
    "        d = self.embedder.get_sentence_embedding_dimension()\n",
    "        self.coin_net = nn.Sequential(\n",
    "            nn.Linear(d*2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, k)\n",
    "        )\n",
    "\n",
    "    def embed_sentences(self, sents: List[str]) -> np.ndarray:\n",
    "        return self.embedder.encode(sents, convert_to_numpy=True)\n",
    "\n",
    "    def build_graph(self, emb: np.ndarray) -> nx.Graph:\n",
    "        sim = cosine_similarity(emb)\n",
    "        n = len(emb)\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(range(n))\n",
    "        for i in range(n):\n",
    "            nbrs = np.argsort(sim[i])[::-1][1:self.k+1]\n",
    "            for j in nbrs:\n",
    "                G.add_edge(i, j, weight=sim[i,j])\n",
    "        return G\n",
    "\n",
    "    def quantum_walk(self, G: nx.Graph, qv: np.ndarray, emb: np.ndarray) -> torch.Tensor:\n",
    "        n, k = G.number_of_nodes(), self.k\n",
    "        state = torch.ones(n,k, dtype=torch.cfloat) / np.sqrt(n*k)\n",
    "        nbr_lists = [list(G.neighbors(i)) for i in range(n)]\n",
    "        q_t = torch.from_numpy(qv).float()\n",
    "        emb_t = torch.from_numpy(emb).float()\n",
    "        for _ in range(self.walk_steps):\n",
    "            coins = []\n",
    "            for i in range(n):\n",
    "                inp = torch.cat([emb_t[i], q_t])\n",
    "                amps = self.coin_net(inp)\n",
    "                c_real = amps.unsqueeze(1) * amps.unsqueeze(0)\n",
    "                coins.append((c_real.to(torch.cfloat)/torch.norm(c_real)))\n",
    "            new_state = torch.zeros_like(state)\n",
    "            for i in range(n):\n",
    "                s_p = coins[i] @ state[i]\n",
    "                for idx,j in enumerate(nbr_lists[i][:k]):\n",
    "                    new_state[j,idx] += s_p[idx]\n",
    "            state = new_state/torch.norm(new_state)\n",
    "        return state.abs().sum(dim=1)\n",
    "\n",
    "    def forward(self, question: str, sents: List[str]) -> List[Tuple[int,float]]:\n",
    "        emb = self.embed_sentences(sents)\n",
    "        qv  = self.embedder.encode([question], convert_to_numpy=True)[0]\n",
    "        G   = self.build_graph(emb)\n",
    "        logits = self.quantum_walk(G, qv, emb).detach().cpu().numpy()\n",
    "        return sorted(enumerate(logits), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: IR + training/test helpers\n",
    "def load_hotpot(fn: str) -> List[Dict]:\n",
    "    return json.load(open(fn))\n",
    "\n",
    "def build_paragraph_index(data, model):\n",
    "    paras = []\n",
    "    for ex in data:\n",
    "        for title, s in ex['context']:\n",
    "            paras.append((title, s))\n",
    "    seen, unique = set(), []\n",
    "    for t,s in paras:\n",
    "        if t not in seen:\n",
    "            seen.add(t); unique.append((t,s))\n",
    "    texts = [' '.join(s) for _,s in unique]\n",
    "    embs  = model.encode(texts, convert_to_numpy=True)\n",
    "    d = embs.shape[1]\n",
    "    idx = faiss.IndexFlatIP(d)\n",
    "    faiss.normalize_L2(embs)\n",
    "    idx.add(embs)\n",
    "    return idx, unique\n",
    "\n",
    "def retrieve_topk(idx, paras, model, qs, k=10):\n",
    "    ids, questions = zip(*qs)\n",
    "    qemb = model.encode(questions, convert_to_numpy=True)\n",
    "    faiss.normalize_L2(qemb)\n",
    "    _, I = idx.search(qemb, k)\n",
    "    return {qid: [paras[i] for i in row] for qid,row in zip(ids, I)}\n",
    "\n",
    "def prepare_train_examples(data):\n",
    "    exs = []\n",
    "    for ex in data:\n",
    "        q = ex['question']\n",
    "        sents, lbls = [], []\n",
    "        for title, slist in ex['context']:\n",
    "            for sid,s in enumerate(slist):\n",
    "                sents.append(s)\n",
    "                lbls.append(1 if [title,sid] in ex.get('supporting_facts',[]) else 0)\n",
    "        exs.append({'question':q,'sentences':sents,'labels':lbls})\n",
    "    return exs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "420eee7a1b2e48afbda298b0be0a4312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch 2/5:   0%|          | 0/90447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 4: TRAIN with checkpointing (resume/save)\n",
    "train_file   = '/data/research/hotpot/hotpot_train_v1.1.json'\n",
    "model_path   = 'coin_net.pth'\n",
    "epochs, lr   = 5, 1e-3\n",
    "checkpoint_dir = 'checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "last_ckpt = os.path.join(checkpoint_dir, 'last.ckpt')\n",
    "\n",
    "# Load data and initialize\n",
    "train_data  = load_hotpot(train_file)\n",
    "examples    = prepare_train_examples(train_data)\n",
    "retriever   = QuantumWalkRetriever()\n",
    "optimizer   = torch.optim.Adam(retriever.coin_net.parameters(), lr=lr)\n",
    "\n",
    "# Resume from checkpoint if exists\n",
    "start_epoch = 0\n",
    "if os.path.exists(last_ckpt):\n",
    "    ckpt = torch.load(last_ckpt)\n",
    "    retriever.coin_net.load_state_dict(ckpt['model_state'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer_state'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "# Training loop\n",
    "for ep in range(start_epoch, epochs):\n",
    "    total_loss = 0.0\n",
    "    for ex in tqdm(examples, desc=f'Train Epoch {ep+1}/{epochs}'):\n",
    "        labels = torch.tensor(ex['labels'], dtype=torch.float)\n",
    "        if labels.sum()>0:\n",
    "            labels /= labels.sum()\n",
    "        emb  = retriever.embed_sentences(ex['sentences'])\n",
    "        qv   = retriever.embedder.encode([ex['question']], convert_to_numpy=True)[0]\n",
    "        G    = retriever.build_graph(emb)\n",
    "        logits = retriever.quantum_walk(G, qv, emb)\n",
    "        probs  = torch.softmax(logits, dim=0)\n",
    "        loss   = F.kl_div(probs.log(), labels, reduction='batchmean')\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(examples)\n",
    "    print(f'Epoch {ep+1}, Avg Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Save checkpoint\n",
    "    ckpt = {\n",
    "        'epoch': ep,\n",
    "        'model_state': retriever.coin_net.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict()\n",
    "    }\n",
    "    torch.save(ckpt, last_ckpt)\n",
    "    torch.save(retriever.coin_net.state_dict(), model_path)\n",
    "\n",
    "print(\"Training complete, final model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
