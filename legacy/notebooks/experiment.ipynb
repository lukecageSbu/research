{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List\n",
    "\n",
    "class QuantumWalkRetriever(nn.Module):\n",
    "    def __init__(self, embed_model_name: str = 'all-MiniLM-L6-v2', k: int = 5, hidden_dim: int = 128, walk_steps: int = 3):\n",
    "        super().__init__()\n",
    "        self.embedder = SentenceTransformer(embed_model_name)\n",
    "        for param in self.embedder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.k = k\n",
    "        self.walk_steps = walk_steps\n",
    "        embedding_dim = self.embedder.get_sentence_embedding_dimension()\n",
    "        self.coin_net = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, k)\n",
    "        )\n",
    "\n",
    "    def embed_sentences(self, sentences: List[str]) -> np.ndarray:\n",
    "        return self.embedder.encode(sentences, convert_to_numpy=True)\n",
    "\n",
    "    def build_graph(self, embeddings: np.ndarray) -> nx.Graph:\n",
    "        sim = cosine_similarity(embeddings)\n",
    "        n = embeddings.shape[0]\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(range(n))\n",
    "        for i in range(n):\n",
    "            neighbors = np.argsort(sim[i])[::-1][1:self.k+1]\n",
    "            for j in neighbors:\n",
    "                G.add_edge(i, j, weight=sim[i, j])\n",
    "        return G\n",
    "\n",
    "    def quantum_walk(self, G: nx.Graph, query_vec: np.ndarray, embeddings: np.ndarray) -> torch.Tensor:\n",
    "        n = G.number_of_nodes()\n",
    "        state = torch.ones(n, self.k, dtype=torch.cfloat) / float(np.sqrt(n * self.k))\n",
    "        nbrs = [list(G.neighbors(i)) for i in range(n)]\n",
    "        q_tensor = torch.from_numpy(query_vec).float()\n",
    "        emb_tensor = torch.from_numpy(embeddings).float()\n",
    "        for _ in range(self.walk_steps):\n",
    "            coins = []\n",
    "            for i in range(n):\n",
    "                inp = torch.cat([emb_tensor[i], q_tensor], dim=0)\n",
    "                amps = self.coin_net(inp)\n",
    "                c_real = amps.unsqueeze(1) * amps.unsqueeze(0)\n",
    "                c = c_real.to(torch.cfloat) / torch.norm(c_real)\n",
    "                coins.append(c)\n",
    "            new_state = torch.zeros_like(state)\n",
    "            for i in range(n):\n",
    "                s_prime = coins[i] @ state[i]\n",
    "                for idx, j in enumerate(nbrs[i][:self.k]):\n",
    "                    new_state[j, idx] += s_prime[idx]\n",
    "            state = new_state / torch.norm(new_state)\n",
    "        logits = state.abs().sum(dim=1)\n",
    "        return logits\n",
    "\n",
    "    def forward(self, question: str, sentences: List[str]) -> List[tuple[int, float]]:\n",
    "        sent_emb = self.embed_sentences(sentences)\n",
    "        q_emb = self.embedder.encode([question], convert_to_numpy=True)[0]\n",
    "        G = self.build_graph(sent_emb)\n",
    "        logits = self.quantum_walk(G, q_emb, sent_emb).detach().cpu().numpy()\n",
    "        return sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def train_coin_operator(self, train_data: List[dict], epochs: int = 5, lr: float = 1e-3):\n",
    "        optimizer = optim.Adam(self.coin_net.parameters(), lr=lr)\n",
    "        self.train()\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            total_loss = 0.0\n",
    "            for ex in train_data:\n",
    "                labels = torch.tensor(ex['labels'], dtype=torch.float)\n",
    "                if labels.sum() > 0:\n",
    "                    labels = labels / labels.sum()\n",
    "                sent_emb = self.embed_sentences(ex['sentences'])\n",
    "                q_emb = self.embedder.encode([ex['question']], convert_to_numpy=True)[0]\n",
    "                G = self.build_graph(sent_emb)\n",
    "                logits = self.quantum_walk(G, q_emb, sent_emb)\n",
    "                probs = torch.softmax(logits, dim=0)\n",
    "                loss = F.kl_div(probs.log(), labels, reduction='batchmean')\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f\"Epoch {epoch}/{epochs}, Loss: {total_loss/len(train_data):.4f}\")\n",
    "        self.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = QuantumWalkRetriever(embed_model_name='all-MiniLM-L6-v2', k=5, hidden_dim=128, walk_steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"The Eiffel Tower is in Paris.\",\n",
    "    \"Paris is the capital of France.\",\n",
    "    \"The Louvre houses the Mona Lisa.\",\n",
    "    \"The Mona Lisa is a portrait by Leonardo da Vinci.\"\n",
    "]\n",
    "question = \"Where can you find the Mona Lisa?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is in Paris. -> score: 0.7101\n",
      "Paris is the capital of France. -> score: 0.6072\n",
      "The Louvre houses the Mona Lisa. -> score: 0.5173\n"
     ]
    }
   ],
   "source": [
    "rankings = retriever.forward(question, documents)\n",
    "for idx, score in rankings[:3]:\n",
    "    print(f\"{documents[idx]} -> score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 0.3518\n",
      "Epoch 2/3, Loss: 0.3172\n",
      "Epoch 3/3, Loss: 0.2721\n"
     ]
    }
   ],
   "source": [
    "train_examples = [\n",
    "    {'question': question, 'sentences': documents, 'labels': [0, 0, 1, 0]}\n",
    "]\n",
    "retriever.train_coin_operator(train_examples, epochs=3, lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
